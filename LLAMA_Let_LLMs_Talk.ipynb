{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaishavi/Let_LLMs_talk/blob/Final-Submission/LLAMA_Let_LLMs_Talk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install replicate"
      ],
      "metadata": {
        "id": "Br3rwkD92kTQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NtGhYCvv6mJF"
      },
      "outputs": [],
      "source": [
        "import replicate\n",
        "import nltk\n",
        "import re\n",
        "import random\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "KTp2-RmFAiTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"REPLICATE_API_TOKEN\"] = \"\"\n",
        "\n",
        "api = replicate.Client(api_token= os.environ[\"REPLICATE_API_TOKEN\"])"
      ],
      "metadata": {
        "id": "raxdQn9dab9v"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_topics(path_to_topics):\n",
        "\n",
        "    with open(path_to_topics, \"r\") as r:\n",
        "        data = r.read()\n",
        "\n",
        "    topics = data.strip().split(TOPIC_SPLITTER)\n",
        "    topics = [topic.strip() for topic in topics if len(topic.strip())>0]\n",
        "\n",
        "    return topics"
      ],
      "metadata": {
        "id": "0Vl8Ha_8pKDj"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_llama(conversation_Log):\n",
        "    input_prompt = ' '.join([turn['content'] for turn in conversation_Log])\n",
        "    input = {\n",
        "        \"prompt\": input_prompt\n",
        "    }\n",
        "    output = replicate.run(\n",
        "        \"meta/meta-llama-3-70b-instruct\",\n",
        "        input=input\n",
        "    )\n",
        "    return conversation_Log[-1]['role'], \"\".join(output)"
      ],
      "metadata": {
        "id": "9sw5HynHpKAb"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre_process_res(response_text):\n",
        "    if response_text.startswith(\"Text:\"):\n",
        "        response_text = response_text.lstrip(\"Text:\")\n",
        "\n",
        "    response_text = response_text.strip()\n",
        "    response_text = response_text.rstrip(\",.;:?!\\\"\\'\")\n",
        "    response_text = response_text.lstrip(\",.;:?!\\\"\\'\")\n",
        "\n",
        "    return response_text"
      ],
      "metadata": {
        "id": "OKnjcx31pJ9k"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_grounded_answers(answer_text, section_text):\n",
        "    sentences = nltk.sent_tokenize(answer_text)\n",
        "    curr_sent = sentences[0]\n",
        "    answers_all = []\n",
        "\n",
        "    for i in range(1, len(sentences)):\n",
        "        x_1 = (curr_sent.strip() + \" \" + sentences[i].strip())\n",
        "        if (x_1 in section_text):\n",
        "            curr_sent = x_1\n",
        "        else:\n",
        "            answers_all.append(curr_sent)\n",
        "            curr_sent = sentences[i]\n",
        "\n",
        "    if not (curr_sent in answers_all):\n",
        "        answers_all.append(curr_sent)\n",
        "\n",
        "    return answers_all"
      ],
      "metadata": {
        "id": "RhpJata9pJ6c"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_overlap(answer_text, section_text):\n",
        "    length = len(answer_text.split())\n",
        "    tmp = answer_text\n",
        "    for i in range(0, int(length/2)):\n",
        "        tmp = tmp.split(' ', 1)[1]\n",
        "        if tmp.lower() in section_text.lower():\n",
        "            return True, tmp\n",
        "    return False, None"
      ],
      "metadata": {
        "id": "JJ47IWnopJ3l"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_teacher_response(response, topic_background, section):\n",
        "    response = pre_process_res(response)\n",
        "\n",
        "    # condition 0\n",
        "    if (response in cannot_find_text) or (cannot_find_text in response) or (\"the text does not\" in response):\n",
        "        print(\"Condition 0\")\n",
        "        return True, [cannot_find_text]\n",
        "\n",
        "    # condition 1\n",
        "    res, tmp_text = check_overlap(response, section)\n",
        "    if res:\n",
        "        print(\"Condition 1\")\n",
        "        return True, [tmp_text]\n",
        "\n",
        "    # condition 2\n",
        "    clean_section = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\\g<1>\\g<2>\", section)\n",
        "    clean_section = ' '.join(clean_section.split())\n",
        "\n",
        "    res, tmp_text = check_overlap(response, clean_section)\n",
        "    if res:\n",
        "        print(\"Condition 2\")\n",
        "        return True, [tmp_text]\n",
        "\n",
        "    # condition 3\n",
        "    sentencess = get_grounded_answers(response, section)\n",
        "\n",
        "    answer_spans = []\n",
        "\n",
        "    for sent in sentencess:\n",
        "        if len(sent) > 0:\n",
        "            sent_clean = pre_process_res(sent)\n",
        "            res, tmp_text = check_overlap(sent_clean, section)\n",
        "            if res:\n",
        "                answer_spans.append(tmp_text)\n",
        "\n",
        "    if len(answer_spans) > 0:\n",
        "        print(\"Condition 3\")\n",
        "        return True, answer_spans\n",
        "\n",
        "    # condition 5\n",
        "    if response in topic_background:\n",
        "        print(\"Condition 4\")\n",
        "        return False, [prompt_answer_from_text]\n",
        "\n",
        "    return False, [prompt_copy_exact_segment]"
      ],
      "metadata": {
        "id": "vrqUNGsGpJ0c"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def teacher_process_one_question(index, doc_info, question):\n",
        "\n",
        "    title, background, header, section = doc_info\n",
        "\n",
        "    if index == 0:\n",
        "        prompt_input = first_prompt_teacher.format(title=title, background=background, instruction_teacher= instruction_teacher, header=header, section=section, question=question)\n",
        "\n",
        "    else:\n",
        "        prompt_input = prompt_answer_short.format(question=question)\n",
        "\n",
        "    teacher_conversations.append({'role': 'user', 'content': prompt_input})\n",
        "\n",
        "    for i in range(0, TEACHER_PATIENCE):\n",
        "        role, content = run_llama(teacher_conversations)\n",
        "        teacher_conversations.append({'role': role, 'content': content})\n",
        "        res, res_prompt = check_teacher_response(content, doc_info[1], doc_info[3])\n",
        "\n",
        "        if res == True:\n",
        "            gpt_4_answer = res_prompt\n",
        "            break\n",
        "\n",
        "        elif i < 3:\n",
        "            # ask the given prompt\n",
        "            teacher_conversations.append({'role': 'user', 'content': res_prompt[0]})\n",
        "\n",
        "        elif i == 3:\n",
        "            gpt_4_answer = [\"I cannot find the answer. \" + content]\n",
        "            print(\"final answer didn't match!\")\n",
        "\n",
        "    return gpt_4_answer"
      ],
      "metadata": {
        "id": "23nbM_FGpJx2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_question(question):\n",
        "    if \"\\n\" in question or len(question.split()) > MAX_QUES_LENGTH:\n",
        "        return False\n",
        "    return True"
      ],
      "metadata": {
        "id": "tINuf76GpJue"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_student(first_question, title, background, header, prev_answer, prompt_arr_student):\n",
        "\n",
        "    if first_question:\n",
        "        prompt = student_prompt.format(instruction=student_instruction, title=title, background=background, header=header)\n",
        "\n",
        "    elif prev_answer == cannot_find_text:\n",
        "        prompt = random.choice(prompt_arr_student)\n",
        "        print(\"Student selected prompt: \", prompt)\n",
        "        if prompt == interesting_prompt:\n",
        "            prompt_arr_student.remove(interesting_prompt)\n",
        "\n",
        "    else:\n",
        "        prompt = student_prompt_regular\n",
        "\n",
        "    answer_with_prompt = prev_answer + \" \" + prompt\n",
        "    student_conversations.append({'role': 'user', 'content': answer_with_prompt})\n",
        "    role, new_question = run_llama(student_conversations)\n",
        "\n",
        "    while not check_question(new_question):\n",
        "        role, new_question = run_llama(student_conversations)\n",
        "        prompt_2 = answer_with_prompt + \" Please only ask one short question.\"\n",
        "        student_conversations[-1] = {'role': 'user', 'content': prompt_2}\n",
        "\n",
        "    student_conversations.append({'role': role, 'content': new_question})\n",
        "\n",
        "    if prompt == interesting_prompt:\n",
        "        new_question = new_question + \" (tell me maximum number of two segments)\"\n",
        "\n",
        "    return new_question"
      ],
      "metadata": {
        "id": "ODuxOOGMpJox"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def student_teacher_simulation(doc_info):\n",
        "    output_res = {}\n",
        "\n",
        "    prompt_arr_student = [wh_prompt, interesting_prompt, general_prompt, change_aspect]\n",
        "    title, background, header, section = doc_info\n",
        "\n",
        "    output_res['title'] = title\n",
        "    output_res['background'] = background\n",
        "    output_res['header'] = header\n",
        "    output_res['section'] = section\n",
        "    output_res['conversation'] = []\n",
        "\n",
        "\n",
        "    question = simulate_student(True, title, background, header, \"\", prompt_arr_student)\n",
        "    answer_arr = teacher_process_one_question(0, doc_info, question)\n",
        "    tmp= {'question': question,\n",
        "          'answer':answer_arr}\n",
        "    output_res['conversation'].append(tmp)\n",
        "    answer = ' '.join(answer_arr)\n",
        "\n",
        "    for i in range(1, CONV_LENGTH):\n",
        "        question = simulate_student(False, title, background, header, answer, prompt_arr_student)\n",
        "        answer_arr = teacher_process_one_question(i, doc_info, question)\n",
        "        tmp = {'question': question,\n",
        "               'answer': answer_arr}\n",
        "        output_res['conversation'].append(tmp)\n",
        "        answer = ' '.join(answer_arr)\n",
        "\n",
        "    return output_res"
      ],
      "metadata": {
        "id": "GX8YGDg2pJdz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_answer_from_text = \"Please answer from the given section not the given background description.\"\n",
        "prompt_copy_exact_segment = \"Please copy the exact segment from the text.\"\n",
        "cannot_find_text = \"I cannot find the answer.\"\n",
        "prompt_answer_short = \"{question}\\n(Remember that you should select the shortest possible span from the text).\"\n",
        "student_prompt = \"{instruction}\\nBackground:\\n:{title}\\n{background}\\nHeader: {header}\\nPlease start asking questions about: {header}.\"\n",
        "\n",
        "student_instruction = \"\"\"In this task, I am a teacher and have a document, you are a curious student who wants to explore this document by asking questions.\n",
        "The main objective is to learn most of the document that I have. I will give you background knowledge of the document and the title of the document.\n",
        "You should ask questions about this title one by one. When you ask a question, I give you the answer, and then you ask your next question.\n",
        "I’m only allowed to find the answer to your questions from this document, so if I cannot find the answer, I will say “I cannot find the answer, please ask your next question”.\n",
        "You shouldn’t ask questions that can be answered from my previous answers to your previous questions. You should sometimes ask follow-up questions from my previous answers.\"\"\"\n",
        "\n",
        "general_prompt = \"Please ask a general question and don't ask a too specific question.\"\n",
        "wh_prompt = \"Please ask a question starting with where, when, or who.\"\n",
        "interesting_prompt = \"Please ask what is interesting about this document.\"\n",
        "change_aspect = \"Please ask a question about another aspect of the topic.\"\n",
        "student_prompt_regular = \". Please ask your next question.\"\n",
        "prompt_without_ellipsis = \"Please repeat your last question by using Ellipsis and co-references.\"\n",
        "\n"
      ],
      "metadata": {
        "id": "DTO2ZDD2puLz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_topics = \"/content/data_for_simulation.txt\"\n",
        "result_path = './simulated_conversations.txt'\n",
        "TOPIC_SPLITTER = \"<Topic: --------------------------->\"\n",
        "\n",
        "TEACHER_PATIENCE = 4\n",
        "MAX_QUES_LENGTH = 25\n",
        "CONV_LENGTH = 12\n",
        "\n",
        "instruction_teacher = \"\"\"In this task, you will be given a text about the topic explained above. You will answer my questions from this text.  Please remember that you cannot generate the answer on your own but should only copy a continuous span from the original text and the copied answer should not exceed 40 tokens.  If you cannot find the answer in the text, please generate ‘I cannot find the answer’.\"\"\"\n",
        "first_prompt_teacher = \"Topic: {title}\\n{background}\\n{instruction_teacher}\\nText:\\n{header}\\n{section}\\nQuestion: {question}\""
      ],
      "metadata": {
        "id": "I8Lyz0mPpxQ8"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "topics = get_topics(path_to_topics)\n",
        "\n",
        "simulated_convs = []\n",
        "\n",
        "for i in range(0, len(topics)):\n",
        "    teacher_conversations = []\n",
        "    student_conversations = []\n",
        "    doc_info = topics[i].strip().split(\"\\n\")\n",
        "    doc_info[3] = ' '.join(doc_info[3].split()).rstrip(\"CANNOTANSWER\").strip()\n",
        "    doc_info[1] = ' '.join(doc_info[1].split())\n",
        "    output_res = student_teacher_simulation(doc_info)\n",
        "    simulated_convs.append(output_res)\n"
      ],
      "metadata": {
        "id": "uASoxcg-p0tg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(result_path, 'wb') as f:\n",
        "    pickle.dump(simulated_convs, f)"
      ],
      "metadata": {
        "id": "h9cRdUo_fyHm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}